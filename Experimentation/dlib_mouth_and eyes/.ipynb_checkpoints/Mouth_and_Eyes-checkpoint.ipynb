{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19934876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import time\n",
    "import cv2\n",
    "import glob\n",
    "import dlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detect a face in webcam video and check if mouth is open.\n",
    "\"\"\"\n",
    "import face_recognition\n",
    "import cv2\n",
    "from mouth_open_algorithm import get_lip_height, get_mouth_height\n",
    "from datetime import datetime\n",
    "import math\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "def is_mouth_open(face_landmarks):\n",
    "    top_lip = face_landmarks['top_lip']\n",
    "    bottom_lip = face_landmarks['bottom_lip']\n",
    "\n",
    "    top_lip_height = get_lip_height(top_lip)\n",
    "    bottom_lip_height = get_lip_height(bottom_lip)\n",
    "    mouth_height = get_mouth_height(top_lip, bottom_lip)\n",
    "    \n",
    "    # if mouth is open more than lip height * ratio, return true.\n",
    "    ratio = 1.0\n",
    "    print('top_lip_height: %.2f, bottom_lip_height: %.2f, mouth_height: %.2f, min*ratio: %.2f' \n",
    "          % (top_lip_height,bottom_lip_height,mouth_height, min(top_lip_height, bottom_lip_height) * ratio))\n",
    "          \n",
    "    if mouth_height > min(top_lip_height, bottom_lip_height) * ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "   \n",
    "def get_eye_height(eye):\n",
    "    sum=0\n",
    "    width = math.sqrt( (eye[0][0] - eye[4][0])**2 +\n",
    "                          (eye[0][1] - eye[4][1])**2   )\n",
    "    for i in [1,2]:\n",
    "        # distance between two near points up and down\n",
    "        distance = math.sqrt( (eye[i][0] - eye[6-i][0])**2 +\n",
    "                              (eye[i][1] - eye[6-i][1])**2   )\n",
    "        sum += distance\n",
    "    return (sum / 2,width)\n",
    "\n",
    "def are_eyes_open(face_landmarks):\n",
    "    left_eye = face_landmarks['left_eye']\n",
    "    right_eye = face_landmarks['right_eye']\n",
    "\n",
    "    left_eye_height,left_eye_width = get_eye_height(left_eye)\n",
    "    right_eye_height,right_eye_width = get_eye_height(right_eye)\n",
    "    \n",
    "    \n",
    "    # if mouth is open more than lip height * ratio, return true.\n",
    "    ratio = 0.5\n",
    "    print('left_eye_height: %.2f, right_eye_height: %.2f, left_eye: %.2f, right_eye: %.2f' \n",
    "          % (left_eye_height,right_eye_height, left_eye_width * ratio, right_eye_width * ratio))\n",
    "          \n",
    "    if left_eye_height < left_eye_width * ratio and right_eye_height < right_eye_width * ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#Set deque length for voting\n",
    "Q_mouth       = deque(maxlen=5)\n",
    "Q_eyes       = deque(maxlen=5)\n",
    "previous = time.time()\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object to save video to local\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # codec\n",
    "# cv2.VideoWriter( filename, fourcc, fps, frameSize )\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 7, (640, 480)) \n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "# peter_image = face_recognition.load_image_file(\"peter.jpg\") # replace peter.jpg with your own image !!\n",
    "# peter_face_encoding = face_recognition.face_encodings(peter_image)[0]\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    # Find all the faces and face enqcodings in the frame of video\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "\n",
    "    # Loop through each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding, face_landmarks in zip(face_locations, face_encodings, face_landmarks_list):\n",
    "\n",
    "        #  See if the face is a match for the known face(s)\n",
    "#         match = face_recognition.compare_faces([peter_face_encoding], face_encoding)\n",
    "\n",
    "#         name = \"Unknown\"\n",
    "#         if match[0]:\n",
    "#             name = \"Peter\"\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "#         cv2.rectangle(frame, (left, bottom), (right, bottom + 35), (0, 0, 255), cv2.FILLED)\n",
    "#         font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#         cv2.putText(frame, name, (left + 6, bottom + 25), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "        # Display text for mouth open / close\n",
    "        Q_mouth.append(is_mouth_open(face_landmarks))\n",
    "        ret_mouth_open=max(set(Q_mouth), key=Q_mouth.count)\n",
    "        if ret_mouth_open is True:\n",
    "            text = 'Mouth is open'\n",
    "        else:\n",
    "            text = 'Open your mouth'\n",
    "        cv2.putText(frame, text, (left, top - 50), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 0, 0), 1)\n",
    "        \n",
    "        # Display text for eyes open / close\n",
    "        Q_eyes.append(are_eyes_open(face_landmarks))\n",
    "        ret_eyes_open = max(set(Q_eyes), key=Q_eyes.count)\n",
    "        if ret_eyes_open is True:\n",
    "            text = 'Eyes are closed'\n",
    "        else:\n",
    "            text = 'Eyes are open'\n",
    "        cv2.putText(frame, text, (left, bottom + 50), cv2.FONT_HERSHEY_DUPLEX, 1.0, (0, 255, 0), 1)\n",
    "        \n",
    "        new = time.time()\n",
    "        f = int(1/(new - previous))\n",
    "        previous = new\n",
    "        cv2.putText(frame, f'FPS: {f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 1, cv2.LINE_AA )\n",
    "\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a90f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
