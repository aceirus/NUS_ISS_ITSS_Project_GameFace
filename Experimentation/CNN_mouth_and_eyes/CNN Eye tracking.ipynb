{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import tensorflow \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,Activation,Dropout,MaxPooling2D\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#we will use images 26x34x1 (1 is for grayscale images)\n",
    "height = 26\n",
    "width = 34\n",
    "dims = 1\n",
    "\n",
    "def readCsv(path):\n",
    "\n",
    "\twith open(path,'r') as f:\n",
    "\t\t#read the scv file with the dictionary format \n",
    "\t\treader = csv.DictReader(f)\n",
    "\t\trows = list(reader)\n",
    "\n",
    "\t#imgs is a numpy array with all the images\n",
    "\t#tgs is a numpy array with the tags of the images\n",
    "\timgs = np.empty((len(list(rows)),height,width, dims),dtype=np.uint8)\n",
    "\ttgs = np.empty((len(list(rows)),1))\n",
    "\t\t\n",
    "\tfor row,i in zip(rows,range(len(rows))):\n",
    "\t\t\t\n",
    "\t\t#convert the list back to the image format\n",
    "\t\timg = row['image']\n",
    "\t\timg = img.strip('[').strip(']').split(', ')\n",
    "\t\tim = np.array(img,dtype=np.uint8)\n",
    "\t\tim = im.reshape((26,34))\n",
    "\t\tim = np.expand_dims(im, axis=2)\n",
    "\t\timgs[i] = im\n",
    "\n",
    "\t\t#the tag for open is 1 and for close is 0\n",
    "\t\ttag = row['state']\n",
    "\t\tif tag == 'open':\n",
    "\t\t\ttgs[i] = 1\n",
    "\t\telse:\n",
    "\t\t\ttgs[i] = 0\n",
    "\t\n",
    "\t#shuffle the dataset\n",
    "\tindex = np.random.permutation(imgs.shape[0])\n",
    "\timgs = imgs[index]\n",
    "\ttgs = tgs[index]\n",
    "\n",
    "\t#return images and their respective tags\n",
    "\treturn imgs,tgs\t\n",
    "\n",
    "#make the convolution neural network\n",
    "def makeModel():\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tmodel.add(Conv2D(32, (3,3), padding = 'same', input_shape=(height,width,dims)))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\tmodel.add(Conv2D(64, (2,2), padding= 'same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(128, (2,2), padding='same'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.add(Activation('sigmoid'))\n",
    "\n",
    "\t\n",
    "\tmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\treturn model\n",
    "\n",
    "def main():\n",
    "\n",
    "\txTrain ,yTrain = readCsv('dataset_eyes.csv')\n",
    "\tprint (xTrain.shape[0])\n",
    "\t#scale the values of the images between 0 and 1\n",
    "\txTrain = xTrain.astype('float32')\n",
    "\txTrain /= 255\n",
    "\n",
    "\tmodel = makeModel()\n",
    "\n",
    "\t#do some data augmentation\n",
    "\tdatagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        )\n",
    "\tdatagen.fit(xTrain)\n",
    "\n",
    "\t#train the model\n",
    "\tmodel.fit_generator(datagen.flow(xTrain,yTrain,batch_size=32),\n",
    "\t\t\t\t\t\tsteps_per_epoch=len(xTrain) / 32, epochs=50)\n",
    "\t\n",
    "\t#save the model\n",
    "\tmodel.save('blinkModel.hdf5')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1834a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import face_utils\n",
    "\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# detect the face rectangle \n",
    "def detect(img, cascade = face_cascade , minimumFeatureSize=(20, 20)):\n",
    "    if cascade.empty():\n",
    "        raise (Exception(\"There was a problem loading your Haar Cascade xml file.\"))\n",
    "    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=1, minSize=minimumFeatureSize)\n",
    "    \n",
    "    # if it doesn't return rectangle return array\n",
    "    # with zero lenght\n",
    "    if len(rects) == 0:\n",
    "        return []\n",
    "\n",
    "    #  convert last coord from (width,height) to (maxX, maxY)\n",
    "    rects[:, 2:] += rects[:, :2]\n",
    "\n",
    "    return rects\n",
    "\n",
    "def cropEyes(frame):\n",
    "\t \n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\n",
    "\t# detect the face at grayscale image\n",
    "\tte = detect(gray, minimumFeatureSize=(80, 80))\n",
    "\n",
    "\t# if the face detector doesn't detect face\n",
    "\t# return None, else if detects more than one faces\n",
    "\t# keep the bigger and if it is only one keep one dim\n",
    "\tif len(te) == 0:\n",
    "\t\treturn None\n",
    "\telif len(te) > 1:\n",
    "\t\tface = te[0]\n",
    "\telif len(te) == 1:\n",
    "\t\t[face] = te\n",
    "\n",
    "\t# keep the face region from the whole frame\n",
    "\tface_rect = dlib.rectangle(left = int(face[0]), top = int(face[1]),\n",
    "\t\t\t\t\t\t\t\tright = int(face[2]), bottom = int(face[3]))\n",
    "\t\n",
    "\t# determine the facial landmarks for the face region\n",
    "\tshape = predictor(gray, face_rect)\n",
    "\tshape = face_utils.shape_to_np(shape)\n",
    "\n",
    "\t#  grab the indexes of the facial landmarks for the left and\n",
    "\t#  right eye, respectively\n",
    "\t(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "\t(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "\t# extract the left and right eye coordinates\n",
    "\tleftEye = shape[lStart:lEnd]\n",
    "\trightEye = shape[rStart:rEnd]\n",
    "\n",
    "\t# keep the upper and the lower limit of the eye \n",
    "\t# and compute the height \n",
    "\tl_uppery = min(leftEye[1:3,1])\n",
    "\tl_lowy = max(leftEye[4:,1])\n",
    "\tl_dify = abs(l_uppery - l_lowy)\n",
    "\n",
    "\t# compute the width of the eye\n",
    "\tlw = (leftEye[3][0] - leftEye[0][0])\n",
    "\n",
    "\t# we want the image for the cnn to be (26,34)\n",
    "\t# so we add the half of the difference at x and y\n",
    "\t# axis from the width at height respectively left-right\n",
    "\t# and up-down \n",
    "\tminxl = (leftEye[0][0] - ((34-lw)/2))\n",
    "\tmaxxl = (leftEye[3][0] + ((34-lw)/2)) \n",
    "\tminyl = (l_uppery - ((26-l_dify)/2))\n",
    "\tmaxyl = (l_lowy + ((26-l_dify)/2))\n",
    "\t\n",
    "\t# crop the eye rectangle from the frame\n",
    "\tleft_eye_rect = np.rint([minxl, minyl, maxxl, maxyl])\n",
    "\tleft_eye_rect = left_eye_rect.astype(int)\n",
    "\tleft_eye_image = gray[(left_eye_rect[1]):left_eye_rect[3], (left_eye_rect[0]):left_eye_rect[2]]\n",
    "\t\n",
    "\t# same as left eye at right eye\n",
    "\tr_uppery = min(rightEye[1:3,1])\n",
    "\tr_lowy = max(rightEye[4:,1])\n",
    "\tr_dify = abs(r_uppery - r_lowy)\n",
    "\trw = (rightEye[3][0] - rightEye[0][0])\n",
    "\tminxr = (rightEye[0][0]-((34-rw)/2))\n",
    "\tmaxxr = (rightEye[3][0] + ((34-rw)/2))\n",
    "\tminyr = (r_uppery - ((26-r_dify)/2))\n",
    "\tmaxyr = (r_lowy + ((26-r_dify)/2))\n",
    "\tright_eye_rect = np.rint([minxr, minyr, maxxr, maxyr])\n",
    "\tright_eye_rect = right_eye_rect.astype(int)\n",
    "\tright_eye_image = gray[right_eye_rect[1]:right_eye_rect[3], right_eye_rect[0]:right_eye_rect[2]]\n",
    "\n",
    "\t# if it doesn't detect left or right eye return None\n",
    "\tif 0 in left_eye_image.shape or 0 in right_eye_image.shape:\n",
    "\t\treturn None\n",
    "\t# resize for the conv net\n",
    "\tleft_eye_image = cv2.resize(left_eye_image, (34, 26))\n",
    "\tright_eye_image = cv2.resize(right_eye_image, (34, 26))\n",
    "\tright_eye_image = cv2.flip(right_eye_image, 1)\n",
    "\t# return left and right eye\n",
    "\treturn left_eye_image, right_eye_image \n",
    "\n",
    "# make the image to have the same format as at training \n",
    "def cnnPreprocess(img):\n",
    "\timg = img.astype('float32')\n",
    "\timg /= 255\n",
    "\timg = np.expand_dims(img, axis=2)\n",
    "\timg = np.expand_dims(img, axis=0)\n",
    "\treturn img\n",
    "\n",
    "def main():\n",
    "\t# open the camera,load the cnn model \n",
    "\tcamera = cv2.VideoCapture(0)\n",
    "\tmodel = load_model('blinkModel.hdf5')\n",
    "\t\n",
    "\t# blinks is the number of total blinks ,close_counter\n",
    "\t# the counter for consecutive close predictions\n",
    "\t# and mem_counter the counter of the previous loop \n",
    "\tclose_counter = blinks = mem_counter= 0\n",
    "\tstate = ''\n",
    "\twhile True:\n",
    "\t\t\n",
    "\t\tret, frame = camera.read()\n",
    "\t\t\n",
    "\t\t# detect eyes\n",
    "\t\teyes = cropEyes(frame)\n",
    "\t\tif eyes is None:\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tleft_eye,right_eye = eyes\n",
    "\t\t\n",
    "\t\t# average the predictions of the two eyes \n",
    "\t\tprediction = (model.predict(cnnPreprocess(left_eye)) + model.predict(cnnPreprocess(right_eye)))/2.0\n",
    "\t\t\t\n",
    "\t\t# blinks\n",
    "\t\t# if the eyes are open reset the counter for close eyes\n",
    "\t\tif prediction > 0.5 :\n",
    "\t\t\tstate = 'open'\n",
    "\t\t\tclose_counter = 0\n",
    "\t\telse:\n",
    "\t\t\tstate = 'close'\n",
    "\t\t\tclose_counter += 1\n",
    "\t\t\n",
    "\t\t# if the eyes are open and previousle were closed\n",
    "\t\t# for sufficient number of frames then increcement \n",
    "\t\t# the total blinks\n",
    "\t\tif state == 'open' and mem_counter > 1:\n",
    "\t\t\tblinks += 1\n",
    "\t\t# keep the counter for the next loop \n",
    "\t\tmem_counter = close_counter \n",
    "\n",
    "\t\t# draw the total number of blinks on the frame along with\n",
    "\t\t# the state for the frame\n",
    "\t\tcv2.putText(frame, \"Blinks: {}\".format(blinks), (10, 30),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\t\tcv2.putText(frame, \"State: {}\".format(state), (300, 30),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\t\t\n",
    "\t\t# show the frame\n",
    "\t\tcv2.imshow('blinks counter', frame)\n",
    "\t\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t\t# if the `q` key was pressed, break from the loop\n",
    "\t\tif key == ord('q'):\n",
    "\t\t\tbreak\n",
    "\t# do a little clean up\n",
    "\tcv2.destroyAllWindows()\n",
    "\tdel(camera)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225eeb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
