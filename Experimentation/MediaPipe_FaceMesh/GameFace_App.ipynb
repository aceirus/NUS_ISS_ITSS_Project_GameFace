{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015ea033-ede9-4a4d-8a9f-6ab6a4c128f3",
   "metadata": {},
   "source": [
    "# GameFace\n",
    "HCI With Head Pose Using Computer Vision\n",
    "\n",
    "---\n",
    "Practice Module: Intelligent Sensing System (ISS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e45cd-b361-420f-9838-75b6abd59a05",
   "metadata": {},
   "source": [
    "# 0. File Path & Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf917b8c-7235-48f8-8d98-60df858eb55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "-------------------------\n",
      "pandas:       1.3.3\n",
      "numpy:        1.19.5\n",
      "opencv:       4.5.3\n"
     ]
    }
   ],
   "source": [
    "# Load All Necessary Packages\n",
    "\n",
    "import os\n",
    "# from google.colab import drive\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import winsound\n",
    "import webbrowser\n",
    "import pyautogui\n",
    "import pygetwindow as gw\n",
    "import mediapipe as mp\n",
    "seed = 12\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"-------------------------\")\n",
    "print(\"pandas:      \", pd.__version__)\n",
    "print(\"numpy:       \", np.__version__)\n",
    "print(\"opencv:      \", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3851193-54cc-427e-b05f-3030ff0a3548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\Personal\\\\Education\\\\NUS-ISS Mtech IS\\\\Course Materials\\\\3. Intelligent Sensing Systems (ISS)\\\\0. Practice Module (TT)\\\\Source Code\\\\Face Pose Estimation 1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Mounting to Google Drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# # Change Working Directory\n",
    "# os.chdir('/content/gdrive/My Drive/iss/prs_pm/training')\n",
    "\n",
    "print('Working Directory: ')\n",
    "# !pwd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6ab18-0c4d-427c-a749-c8671b4c9112",
   "metadata": {},
   "source": [
    "# 1. Load Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7cb27c6-603a-4e98-8eda-22eee38c6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Config Files\n",
    "config_file = 'configs.txt'\n",
    "openconfig = open(config_file, 'r')\n",
    "config_read = openconfig.readlines()\n",
    "openconfig.close()\n",
    "configs = [x.strip() for x in config_read]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb0c73b-e2fe-43cd-bae9-2b9af16458a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Config Information\n",
    "\n",
    "# Extract Landmarks Index\n",
    "eye_left           = np.array(np.array(configs)[np.array(['eye_left' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "eye_right          = np.array(np.array(configs)[np.array(['eye_right' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "mouth_upper_top    = np.array(np.array(configs)[np.array(['mouth_upper_top' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "mouth_upper_bottom = np.array(np.array(configs)[np.array(['mouth_upper_bottom' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "mouth_lower_top    = np.array(np.array(configs)[np.array(['mouth_lower_top' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "mouth_lower_bottom = np.array(np.array(configs)[np.array(['mouth_lower_bottom' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "cheek_left         = np.array(np.array(configs)[np.array(['cheek_left' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "cheek_right        = np.array(np.array(configs)[np.array(['cheek_right' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "eye_tip_left       = np.array(np.array(configs)[np.array(['eye_tip_left' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "nose_bridge        = np.array(np.array(configs)[np.array(['nose_bridge' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "eye_tip_right      = np.array(np.array(configs)[np.array(['eye_tip_right' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "forehead_upper     = np.array(np.array(configs)[np.array(['forehead_upper' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "forehead_lower     = np.array(np.array(configs)[np.array(['forehead_lower' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "chin_upper         = np.array(np.array(configs)[np.array(['chin_upper' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "chin_lower         = np.array(np.array(configs)[np.array(['chin_lower' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(int)\n",
    "\n",
    "# Extract Action Inference Threshold\n",
    "eye_thres   = np.array(np.array(configs)[np.array(['eye_thres' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "mouth_thres = np.array(np.array(configs)[np.array(['mouth_thres' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "roll_thres  = np.array(np.array(configs)[np.array(['roll_thres' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "yaw_thres   = np.array(np.array(configs)[np.array(['yaw_thres' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "pitch_thres = np.array(np.array(configs)[np.array(['pitch_thres' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "\n",
    "# Extract Action Inference Labels\n",
    "eye_lab   = np.array([x.strip() for x in np.array(configs)[np.array(['eye_lab' in x for x in config_read])][0].split('=')[-1].strip().split(',')])\n",
    "mouth_lab = np.array([x.strip() for x in np.array(configs)[np.array(['mouth_lab' in x for x in config_read])][0].split('=')[-1].strip().split(',')])\n",
    "roll_lab  = np.array([x.strip() for x in np.array(configs)[np.array(['roll_lab' in x for x in config_read])][0].split('=')[-1].strip().split(',')])\n",
    "yaw_lab   = np.array([x.strip() for x in np.array(configs)[np.array(['yaw_lab' in x for x in config_read])][0].split('=')[-1].strip().split(',')])\n",
    "pitch_lab = np.array([x.strip() for x in np.array(configs)[np.array(['pitch_lab' in x for x in config_read])][0].split('=')[-1].strip().split(',')])\n",
    "\n",
    "# Extract Action Controls\n",
    "eyes_crtl       = np.array(configs)[np.array(['eyes_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "mouth_crtl      = np.array(configs)[np.array(['mouth_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "pitch_up_crtl   = np.array(configs)[np.array(['pitch_up_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "pitch_down_crtl = np.array(configs)[np.array(['pitch_down_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "yaw_left_crtl   = np.array(configs)[np.array(['yaw_left_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "yaw_right_crtl  = np.array(configs)[np.array(['yaw_right_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "roll_left_crtl  = np.array(configs)[np.array(['roll_left_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "roll_right_crtl = np.array(configs)[np.array(['roll_right_crtl' in x for x in config_read])][0].split('=')[-1].strip()\n",
    "\n",
    "# Extract Action Time Holding Threshold\n",
    "eye_close_hold     = np.array(np.array(configs)[np.array(['eye_close_hold' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "mouth_open_hold    = np.array(np.array(configs)[np.array(['mouth_open_hold' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "command_exec_thres = np.array(np.array(configs)[np.array(['command_exec_thres' in x for x in config_read])][0].split('=')[-1].strip().split(',')).astype(float)[0]\n",
    "\n",
    "# Extract Target Webpage\n",
    "webpage = np.array(configs)[np.array(['webpage' in x for x in config_read])][0].split('=')[-1].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a3d4a-d4c3-4e55-b329-c9213545334c",
   "metadata": {},
   "source": [
    "# 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c571b02-89b1-44f5-be1a-7c026f5074c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "\n",
    "# Convert Mediapipe Landmark to 2D Coordinates\n",
    "def unnormalize_point(landmark, shape):\n",
    "    x = landmark.x\n",
    "    y = landmark.y\n",
    "    un_norm_x = int(x*shape[1])\n",
    "    un_norm_y = int(y*shape[0])\n",
    "    return np.array([un_norm_x, un_norm_y])\n",
    "\n",
    "# Calculate Euclidean Distance of 2 points\n",
    "def calc_distance_pts(point1, point2):\n",
    "    distance = np.linalg.norm(point1-point2)\n",
    "    return distance\n",
    "\n",
    "# Calculate average Euclidean Distance of 2 list points:\n",
    "def calc_distance_list(list1, list2):\n",
    "    distance = np.mean((np.sum((list1-list2)**2, axis=1))**0.5)\n",
    "    return distance\n",
    "\n",
    "# Calibration of Roll, Yaw, Pitch\n",
    "def calibrate_roll(degree, y1,y2):\n",
    "    if y2 >= y1:\n",
    "        result = degree\n",
    "    else:\n",
    "        result = -degree\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff35e92-cd4c-4901-aa8e-1d4b1436efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Inference Functions (Heuristic Based)\n",
    "\n",
    "# 1. Eye_Closed\n",
    "def are_eyes_close(landmarks, eye_left, eye_right, shape, threshold):\n",
    "    \n",
    "    eye_left_height = calc_distance_pts(unnormalize_point(landmarks[eye_left[0]], shape), unnormalize_point(landmarks[eye_left[2]], shape))\n",
    "    eye_left_width = calc_distance_pts(unnormalize_point(landmarks[eye_left[1]], shape), unnormalize_point(landmarks[eye_left[3]], shape))\n",
    "\n",
    "    eye_right_height = calc_distance_pts(unnormalize_point(landmarks[eye_right[0]], shape), unnormalize_point(landmarks[eye_right[2]], shape))\n",
    "    eye_right_width = calc_distance_pts(unnormalize_point(landmarks[eye_right[1]], shape), unnormalize_point(landmarks[eye_right[3]], shape))\n",
    "\n",
    "    if eye_left_height < eye_left_width * threshold and eye_right_height < eye_right_width * threshold:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "# 2. Mouth Opened\n",
    "def are_mouth_open(landmarks, mouth_upper_top, mouth_upper_bottom, mouth_lower_top, mouth_lower_bottom, shape, threshold):\n",
    "    unnorm_mouth_upper_top = np.array([unnormalize_point(landmarks[x], shape) for x in mouth_upper_top])\n",
    "    unnorm_mouth_upper_bottom = np.array([unnormalize_point(landmarks[x], shape) for x in mouth_upper_bottom])\n",
    "    unnorm_mouth_lower_top = np.array([unnormalize_point(landmarks[x], shape) for x in mouth_lower_top])\n",
    "    unnorm_mouth_lower_bottom = np.array([unnormalize_point(landmarks[x], shape) for x in mouth_lower_bottom])\n",
    "    \n",
    "    lip_upper_avg_height = calc_distance_list(unnorm_mouth_upper_top, unnorm_mouth_upper_bottom)\n",
    "    lip_lower_avg_height = calc_distance_list(unnorm_mouth_lower_top, unnorm_mouth_lower_bottom)\n",
    "    \n",
    "    lip_open_space_avg_height = calc_distance_list(unnorm_mouth_upper_bottom, unnorm_mouth_lower_top)\n",
    "    \n",
    "    if lip_open_space_avg_height > (lip_upper_avg_height + lip_lower_avg_height) * threshold:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "# 3. Roll Left or Right\n",
    "def roll_calc(landmarks, cheek_left, cheek_right, shape):\n",
    "    unnorm_cheek_left = unnormalize_point(landmarks[cheek_left[0]], shape)\n",
    "    unnorm_cheek_right = unnormalize_point(landmarks[cheek_right[0]], shape)\n",
    "    \n",
    "    x1 = unnorm_cheek_left[0]\n",
    "    y1 = unnorm_cheek_left[1]\n",
    "    x2 = unnorm_cheek_right[0]\n",
    "    y2 = unnorm_cheek_right[1]\n",
    "    \n",
    "    height = abs(y2 - y1)\n",
    "    width = abs(x2 - x1)\n",
    "    \n",
    "    degree = np.arctan(height/width)*180/np.pi\n",
    "    return degree, y1, y2\n",
    "\n",
    "\n",
    "def roll_trigger(degree, y1, y2, neutral, threshold):\n",
    "    if degree-neutral > threshold and y2 > y1:\n",
    "        result = 1\n",
    "    elif degree+neutral > threshold and y2 <= y1:\n",
    "        result = -1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "\n",
    "# 4. Yaw Left or Right (neutral ratio basis = left/right)\n",
    "def yaw_calc(landmarks, eye_tip_left, nose_bridge, eye_tip_right, shape):\n",
    "    left2mid_dist = calc_distance_pts(unnormalize_point(landmarks[eye_tip_left[0]], shape), unnormalize_point(landmarks[nose_bridge[0]], shape))\n",
    "    right2mid_dist = calc_distance_pts(unnormalize_point(landmarks[eye_tip_right[0]], shape), unnormalize_point(landmarks[nose_bridge[0]], shape))\n",
    "    return right2mid_dist, left2mid_dist\n",
    "    \n",
    "\n",
    "def yaw_trigger(left2mid_dist, right2mid_dist, neutral, threshold):\n",
    "    if right2mid_dist > left2mid_dist * threshold / neutral:\n",
    "        result = 1\n",
    "    elif left2mid_dist > right2mid_dist * threshold * neutral:\n",
    "        result = -1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "# 5. Pitch Up or Down (neutral ratio basis = upper_dist/lower_dist)\n",
    "def pitch_calc(landmarks, forehead_upper, forehead_lower, chin_upper, chin_lower, shape):\n",
    "    y_forehead_upper = (unnormalize_point(landmarks[forehead_upper[0]], shape)[1] + unnormalize_point(landmarks[forehead_upper[1]], shape)[1]) / 2\n",
    "    y_forehead_lower = (unnormalize_point(landmarks[forehead_lower[0]], shape)[1] + unnormalize_point(landmarks[forehead_lower[1]], shape)[1]) / 2\n",
    "    y_chin_upper = (unnormalize_point(landmarks[chin_upper[0]], shape)[1] + unnormalize_point(landmarks[chin_upper[1]], shape)[1]) / 2\n",
    "    y_chin_lower = (unnormalize_point(landmarks[chin_lower[0]], shape)[1] + unnormalize_point(landmarks[chin_lower[1]], shape)[1]) / 2\n",
    "    \n",
    "    upper_dist = abs(y_forehead_upper - y_forehead_lower)\n",
    "    lower_dist = abs(y_chin_upper - y_chin_lower)\n",
    "    return upper_dist, lower_dist\n",
    "    \n",
    "def pitch_trigger(upper_dist, lower_dist, neutral, threshold):\n",
    "    if upper_dist > lower_dist * threshold * neutral:\n",
    "        result = 1\n",
    "    elif lower_dist > upper_dist * threshold / neutral:\n",
    "        result = -1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682cc224-9228-4bf2-b809-84c5036379af",
   "metadata": {},
   "source": [
    "# 3. GameFace Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be923df1-b75e-464c-8872-c160d2afba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Time Recording\n",
    "previous = time.time()\n",
    "\n",
    "# Initial Position\n",
    "neutral_roll = 0 # Neutral Angle\n",
    "neutral_yaw = 1 # Ratio of left to Right\n",
    "neutral_pitch = 1 # Ratio of Up to Down\n",
    "\n",
    "# Status Indicator\n",
    "stdby_mode = True\n",
    "play_mode = False\n",
    "pend_command = True\n",
    "eye_close_time = 0\n",
    "mouth_open_time = 0\n",
    "command_exec_time = 0\n",
    "prev_command = None\n",
    "point_annotation = False\n",
    "\n",
    "# Calibration Euler:\n",
    "cali_roll_list = np.array([])\n",
    "cali_yaw_list = np.array([])\n",
    "cali_pitch_list = np.array([])\n",
    "\n",
    "# Mediapipe FaceMesh Initialization\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, \n",
    "                                  min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Initialize Browser\n",
    "webbrowser.open_new(webpage)\n",
    "time.sleep(1)\n",
    "window_browser = gw.getActiveWindow()\n",
    "pyautogui.hotkey('winleft', 'right')\n",
    "window_active = False\n",
    "\n",
    "# Initialize Controls\n",
    "first_launch = True\n",
    "\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    # Exit Condition\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    # Start reading Image from Webcam\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    # Exit Condition if no image capture\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Preprocessing - Flipping Left Right\n",
    "    frame = cv2.flip(frame,1)\n",
    "    shape = frame.shape\n",
    "    \n",
    "    # Update Current Mode\n",
    "    if stdby_mode and not play_mode:\n",
    "        cv2.putText(frame, 'Standby Mode', (545, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "    elif not stdby_mode and play_mode:\n",
    "        cv2.putText(frame, 'Play Mode', (569, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Detect Landmarks\n",
    "    frame.flags.writeable = False\n",
    "    faces = face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    frame.flags.writeable = True\n",
    "    if faces.multi_face_landmarks is not None:\n",
    "        face_ind = True\n",
    "        all_landmarks = faces.multi_face_landmarks[0].landmark\n",
    "        cv2.putText(frame, 'Face Detected', (543, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "    else:\n",
    "        face_ind = False\n",
    "        cv2.putText(frame, 'No Face Detected', (520, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Update Status of Pending Command or under Latency\n",
    "    if face_ind and pend_command:\n",
    "        cv2.putText(frame, 'Pending Command', (515, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "    elif face_ind and not pend_command:\n",
    "        cv2.putText(frame, 'Breathing Time', (539, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Infer Actions\n",
    "    if face_ind:\n",
    "        eye_close = are_eyes_close(all_landmarks, eye_left, eye_right, shape, eye_thres)\n",
    "        mouth_open = are_mouth_open(all_landmarks, mouth_upper_top, mouth_upper_bottom, mouth_lower_top, mouth_lower_bottom, shape, mouth_thres)\n",
    "        \n",
    "        roll_degree, roll_y1, roll_y2 = roll_calc(all_landmarks, cheek_left, cheek_right, shape)#, neutral_roll, roll_thres)\n",
    "        roll = roll_trigger(roll_degree, roll_y1, roll_y2, neutral_roll, roll_thres)\n",
    "        \n",
    "        yaw_right2mid, yaw_left2mid = yaw_calc(all_landmarks, eye_tip_left, nose_bridge, eye_tip_right, shape)#, neutral_yaw, yaw_thres)\n",
    "        yaw = yaw_trigger(yaw_right2mid, yaw_left2mid, neutral_yaw, yaw_thres)\n",
    "        \n",
    "        pitch_upper_dist, pitch_lower_dist = pitch_calc(all_landmarks, forehead_upper, forehead_lower, chin_upper, chin_lower, shape)\n",
    "        pitch = pitch_trigger(pitch_upper_dist, pitch_lower_dist, neutral_pitch, pitch_thres)\n",
    "        \n",
    "        cv2.putText(frame, eye_lab[eye_close], (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,128,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, mouth_lab[mouth_open], (10, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,128,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, roll_lab[roll+1], (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,128,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, yaw_lab[yaw+1], (10, 105), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,128,255), 1, cv2.LINE_AA)\n",
    "        cv2.putText(frame, pitch_lab[pitch+1], (10, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,128,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Annotate Key Facial Landmarks Used\n",
    "    if face_ind and point_annotation:\n",
    "        key_ldmrk = np.concatenate([eye_left, eye_right, \n",
    "                     mouth_upper_top, mouth_upper_bottom, mouth_lower_top, mouth_lower_bottom, \n",
    "                     cheek_left, cheek_right, \n",
    "                     eye_tip_left, nose_bridge, eye_tip_right, \n",
    "                     forehead_upper, forehead_lower, chin_upper, chin_lower])\n",
    "        key_coord = np.array([unnormalize_point(all_landmarks[x], shape) for x in key_ldmrk])\n",
    "        # Draw Eye Points\n",
    "        for i in key_coord[:8]:\n",
    "            cv2.circle(frame, i, 1, (0,255,0), 1)\n",
    "        # Draw Mouth Points\n",
    "        for i in key_coord[8:20]:\n",
    "            cv2.circle(frame, i, 1, (0,255,0), 1)\n",
    "        # Draw Cheek Line\n",
    "        cv2.line(frame, key_coord[20], key_coord[21], (255,255,255), 1)\n",
    "        # Draw Left Eye Tip to Nose Bridge\n",
    "        cv2.line(frame, key_coord[22], key_coord[23], (255,255,255), 1)\n",
    "        # Draw Right Eye Tip to Nose Bridge\n",
    "        cv2.line(frame, key_coord[23], key_coord[24], (255,255,255), 1)\n",
    "        # Draw ForeHead Upper\n",
    "        cv2.line(frame, key_coord[25], key_coord[26], (255,255,255), 1)\n",
    "        # Draw ForeHead Lower\n",
    "        cv2.line(frame, key_coord[27], key_coord[28], (255,255,255), 1)\n",
    "        # Draw Chin Upper\n",
    "        cv2.line(frame, key_coord[29], key_coord[30], (255,255,255), 1)\n",
    "        # Draw Chin Lower\n",
    "        cv2.line(frame, key_coord[31], key_coord[32], (255,255,255), 1)\n",
    "        \n",
    "        \n",
    "    # Enter Play Mode, Standby Mode -> Play Mode\n",
    "    if face_ind and stdby_mode and not play_mode and pend_command:\n",
    "        # Trigger Play Mode\n",
    "        if eye_close == 1:\n",
    "            cv2.putText(frame, 'Turning On...', (10, 455), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        if eye_close_time == 0 and eye_close == 1:\n",
    "            eye_close_time = time.time()\n",
    "            cali_roll_list = np.append(cali_roll_list, np.array(calibrate_roll(roll_degree, roll_y1, roll_y2)))\n",
    "            cali_yaw_list = np.append(cali_yaw_list, np.array([yaw_right2mid/yaw_left2mid]))\n",
    "            cali_pitch_list = np.append(cali_pitch_list, np.array([pitch_upper_dist/pitch_lower_dist]))\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-eye_close_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        elif eye_close_time > 0 and eye_close == 1 and (time.time()-eye_close_time) >= eye_close_hold:\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-eye_close_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "            stdby_mode=False\n",
    "            play_mode=True\n",
    "            eye_close_time = 0\n",
    "            neutral_roll = np.mean(cali_roll_list)\n",
    "            neutral_yaw = np.mean(cali_yaw_list)\n",
    "            neutral_pitch = np.mean(cali_pitch_list)\n",
    "            cali_roll_list = np.array([])\n",
    "            cali_yaw_list = np.array([])\n",
    "            cali_pitch_list = np.array([])\n",
    "            winsound.Beep(440, 500)\n",
    "            if first_launch:\n",
    "                pyautogui.press(mouth_crtl)\n",
    "                first_launch = False\n",
    "            else:\n",
    "                pyautogui.press(eyes_crtl)\n",
    "        \n",
    "        elif eye_close_time > 0 and eye_close == 1 and (time.time()-eye_close_time) < eye_close_hold:\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-eye_close_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "            cali_roll_list = np.append(cali_roll_list, np.array(calibrate_roll(roll_degree, roll_y1, roll_y2)))\n",
    "            cali_yaw_list = np.append(cali_yaw_list, np.array([yaw_right2mid/yaw_left2mid]))\n",
    "            cali_pitch_list = np.append(cali_pitch_list, np.array([pitch_upper_dist/pitch_lower_dist]))\n",
    "        \n",
    "        elif eye_close_time > 0 and eye_close == 0:\n",
    "            eye_close_time=0\n",
    "            cali_roll_list = np.array([])\n",
    "            cali_yaw_list = np.array([])\n",
    "            cali_pitch_list = np.array([])\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Exit Play Mode, Play Mode -> Standby Mode\n",
    "    if face_ind and not stdby_mode and play_mode and pend_command:\n",
    "        if eye_close == 1:\n",
    "            cv2.putText(frame, 'Turning Off...', (10, 455), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "        if eye_close_time == 0 and eye_close == 1:\n",
    "            eye_close_time = time.time()\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-eye_close_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "        elif eye_close_time > 0 and eye_close == 1 and (time.time()-eye_close_time) >= eye_close_hold:\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-eye_close_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "            stdby_mode=True\n",
    "            play_mode=False\n",
    "            eye_close_time = 0\n",
    "            winsound.Beep(440, 500)\n",
    "            pyautogui.press(eyes_crtl)\n",
    "        elif eye_close_time > 0 and eye_close == 1 and (time.time()-eye_close_time) < eye_close_hold:\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-eye_close_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "        elif eye_close_time > 0 and eye_close == 0:\n",
    "            eye_close_time=0\n",
    "\n",
    "    # Execute Action\n",
    "    if face_ind and not stdby_mode and play_mode and pend_command:\n",
    "        if roll == 1:\n",
    "            command_exec_time = time.time()\n",
    "            prev_command = roll_lab[roll+1]\n",
    "            pend_command = False\n",
    "            pyautogui.press(roll_right_crtl)\n",
    "        elif roll == -1:\n",
    "            command_exec_time = time.time()\n",
    "            prev_command = roll_lab[roll+1]\n",
    "            pend_command = False\n",
    "            pyautogui.press(roll_left_crtl)\n",
    "        elif pitch == 1:\n",
    "            command_exec_time = time.time()\n",
    "            prev_command = pitch_lab[pitch+1]\n",
    "            pend_command = False\n",
    "            pyautogui.press(pitch_up_crtl)\n",
    "        elif pitch == -1:\n",
    "            command_exec_time = time.time()\n",
    "            prev_command = pitch_lab[pitch+1]\n",
    "            pend_command = False\n",
    "            pyautogui.press(pitch_down_crtl)\n",
    "        elif yaw == 1:\n",
    "            command_exec_time = time.time()\n",
    "            prev_command = yaw_lab[yaw+1]\n",
    "            pend_command = False\n",
    "            pyautogui.press(yaw_right_crtl)\n",
    "        elif yaw == -1:\n",
    "            command_exec_time = time.time()\n",
    "            prev_command = yaw_lab[yaw+1]\n",
    "            pend_command = False\n",
    "            pyautogui.press(yaw_left_crtl)\n",
    "\n",
    "    \n",
    "    # Trigger for Mouth\n",
    "    if face_ind and not stdby_mode and play_mode and pend_command:\n",
    "        if mouth_open_time == 0 and mouth_open == 1:\n",
    "            mouth_open_time = time.time()\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-mouth_open_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "        elif mouth_open_time > 0 and mouth_open == 1 and (time.time()-mouth_open_time) >= mouth_open_hold:\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-mouth_open_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "            mouth_open_time = 0\n",
    "            pyautogui.press(mouth_crtl)\n",
    "        elif mouth_open_time > 0 and mouth_open == 1 and (time.time()-mouth_open_time) < mouth_open_hold:\n",
    "            cv2.putText(frame, 'Hold Time  : {0:0.2f}'.format(round(time.time()-mouth_open_time,2)), (10, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "        elif mouth_open_time > 0 and mouth_open == 0:\n",
    "            mouth_open_time=0\n",
    "    \n",
    "    \n",
    "    # Breathing Period\n",
    "    if face_ind and not stdby_mode and play_mode and not pend_command:\n",
    "        if (time.time()-command_exec_time) >= command_exec_thres:\n",
    "            command_exec_time = 0\n",
    "            prev_command = None\n",
    "            pend_command = True\n",
    "        else:\n",
    "            cv2.putText(frame, 'Action', (595, 455), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f'{prev_command}', (570, 470), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255), 1, cv2.LINE_AA)\n",
    "               \n",
    "    # Refresh FPS\n",
    "    new = time.time()\n",
    "    f = int(1/(new - previous))\n",
    "    previous = new \n",
    "    cv2.putText(frame, 'FPS  : {0:d}'.format(f), (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    # Showing Image Result\n",
    "    winname = \"Test\"\n",
    "    cv2.namedWindow(winname)       \n",
    "    cv2.moveWindow(winname, 1000,300)\n",
    "    cv2.imshow(winname, frame)\n",
    "    \n",
    "    # Switching to application window\n",
    "    if not window_active:\n",
    "        window_active=True\n",
    "        window_browser.activate()\n",
    "    \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()       \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39_gpu1]",
   "language": "python",
   "name": "conda-env-py39_gpu1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
